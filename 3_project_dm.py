# -*- coding: utf-8 -*-
"""3 PROJECT DM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c1ZLcvzagiJ1UaWHWzNYyS2IitebTqUC

Setup Environment dan Drive
"""

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

# Import library utama
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

print("✅ Colab ready + Drive mounted")

"""Load Dataset dari Drive"""

file_path = '/content/drive/MyDrive/complete_data.csv'

df = pd.read_csv(file_path)

print("✅ Dataset loaded from Drive")
print("Shape:", df.shape)
print("\nColumns:", df.columns.tolist())
print("\nMissing values per kolom:\n", df.isnull().sum())

display(df.head())

"""  Data Preparation"""

# 1. Cleaning
def clean_data(df):
    df_clean = df.copy()

    # Isi missing koordinat pake rata-rata provinsi
    if 'lat' in df_clean.columns and 'long' in df_clean.columns:
        df_clean['lat'] = df_clean.groupby('province_name')['lat'].transform(
            lambda x: x.fillna(x.mean()))
        df_clean['long'] = df_clean.groupby('province_name')['long'].transform(
            lambda x: x.fillna(x.mean()))

    # Isi kategori kosong jadi 'Unknown'
    for col in ['stage', 'status', 'province_name', 'city_name']:
        if col in df_clean.columns:
            df_clean[col] = df_clean[col].fillna('Unknown')

    return df_clean

df_clean = clean_data(df)

# 2. Feature Engineering
def feature_engineering(df_in):
    df_fe = df_in.copy()

    # Kepadatan penduduk per luas wilayah provinsi
    df_fe['population_density'] = (
        df_fe['total_population'] / df_fe['province_area']
    )

    # Kepadatan penduduk usia sekolah per luas wilayah
    df_fe['education_density'] = (
        df_fe['total_education_age_population'] / df_fe['province_area']
    )

    # Rasio usia sekolah terhadap total penduduk
    df_fe['education_ratio'] = (
        df_fe['total_education_age_population'] / df_fe['total_population']
    )

    # Encode jenjang sekolah
    level_mapping = {'SD': 1, 'SMP': 2, 'SMA': 3, 'SMK': 3, 'SLB': 4}
    df_fe['school_level'] = df_fe['stage'].map(level_mapping)

    # Encode status sekolah
    df_fe['is_public'] = (df_fe['status'].astype(str).str.upper().str.startswith('N')).astype(int)

    return df_fe

df_fe = feature_engineering(df_clean)

# 3. Label encode provinsi ke angka
le_province = LabelEncoder()
df_fe['province_encoded'] = le_province.fit_transform(df_fe['province_name'])

print("✅ Cleaning + Feature Engineering done")
display(df_fe.head())

"""Data Transformation untuk Model"""

# Kolom fitur untuk clustering wilayah
cluster_features = [
    'population_density',
    'education_density',
    'education_ratio',
    'school_level',
    'is_public',
    'province_encoded'
]

X_cluster = df_fe[cluster_features].dropna()

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_cluster)

print("✅ Data siap untuk clustering (KMeans)")
print("X_cluster shape:", X_cluster.shape)

"""Clustering (KMeans)"""

inertia = []
sil_scores = []

k_range = range(2, 8)
for k in k_range:
    km_tmp = KMeans(n_clusters=k, random_state=42)
    labels_tmp = km_tmp.fit_predict(X_scaled)
    inertia.append(km_tmp.inertia_)
    sil_scores.append(silhouette_score(X_scaled, labels_tmp))

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
plt.plot(k_range, inertia, 'bo-')
plt.xlabel('k (num clusters)')
plt.ylabel('Inertia')
plt.title('Elbow Method')

plt.subplot(1,2,2)
plt.plot(k_range, sil_scores, 'ro-')
plt.xlabel('k (num clusters)')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Analysis')

plt.tight_layout()
plt.show()

# pilih jumlah cluster
optimal_k = 4

kmeans = KMeans(n_clusters=optimal_k, random_state=42)
cluster_labels = kmeans.fit_predict(X_scaled)

# simpan label cluster balik ke df_fe
df_fe['cluster'] = pd.Series([np.nan]*len(df_fe), dtype="float")
df_fe.loc[X_cluster.index, 'cluster'] = cluster_labels

print("✅ Clustering selesai, dipakai k =", optimal_k)
df_fe[['province_name','city_name','stage','status','cluster']].head(10)

"""Classification (Random Forest)"""

class_features = [
    'population_density',
    'education_density',
    'education_ratio',
    'school_level',
    'province_encoded',
    'lat',
    'long'
]

# Buat X dan y untuk klasifikasi
X_class = df_fe[class_features].dropna()
y_class = df_fe.loc[X_class.index, 'is_public']

# Split dataset train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_class,
    y_class,
    test_size=0.3,
    random_state=42,
    stratify=y_class
)

rf_classifier = RandomForestClassifier(
    n_estimators=100,
    random_state=42
)
rf_classifier.fit(X_train, y_train)

y_pred = rf_classifier.predict(X_test)

print("✅ Model RandomForest selesai dilatih")

"""Evaluation"""

# Evaluasi clustering
print("=== CLUSTERING EVALUATION ===")
sil = silhouette_score(X_scaled, cluster_labels)
print(f"Silhouette Score: {sil:.3f}")

cluster_summary = df_fe.groupby('cluster')[[
    'population_density',
    'education_density',
    'education_ratio',
    'is_public'
]].mean().round(3)
print("\nCluster Characteristics:")
display(cluster_summary)

# Evaluasi classification
print("\n=== CLASSIFICATION EVALUATION ===")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Prediksi Status Sekolah (Negeri vs Swasta)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Feature importance dari Random Forest
feature_importance = pd.DataFrame({
    'feature': class_features,
    'importance': rf_classifier.feature_importances_
}).sort_values('importance', ascending=False)

print("Feature Importance:")
display(feature_importance)

print("✅ Evaluation done")

"""Visualisasi Cluster"""

plt.figure(figsize=(15,5))

# Plot 1: cluster berdasarkan density pendidikan
plt.subplot(1,3,1)
for c in sorted(df_fe['cluster'].dropna().unique()):
    subset = df_fe[df_fe['cluster'] == c]
    plt.scatter(
        subset['population_density'],
        subset['education_density'],
        alpha=0.6,
        label=f'Cluster {int(c)}'
    )
plt.xlabel('Population Density')
plt.ylabel('Education Density')
plt.title('Cluster by Density')
plt.legend()

# Plot 2: peta kasar longitude / latitude
plt.subplot(1,3,2)
scatter = plt.scatter(
    df_fe['long'],
    df_fe['lat'],
    c=df_fe['cluster'],
    cmap='viridis',
    alpha=0.6
)
plt.colorbar(scatter, label='Cluster')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('Geographical Distribution of Clusters')

# Plot 3: komposisi negeri vs swasta per cluster
plt.subplot(1,3,3)
cluster_status = pd.crosstab(df_fe['cluster'], df_fe['is_public'])
cluster_status.plot(kind='bar', stacked=True, ax=plt.gca())
plt.title('School Status Distribution per Cluster')
plt.xlabel('Cluster')
plt.ylabel('Count')

plt.tight_layout()
plt.show()

print("✅ Visualisasi cluster OK")

"""Deployment dan Report"""

joblib.dump(kmeans, '/content/drive/MyDrive/education_cluster_model.pkl')
joblib.dump(rf_classifier, '/content/drive/MyDrive/school_status_predictor.pkl')
joblib.dump(scaler, '/content/drive/MyDrive/feature_scaler.pkl')
joblib.dump(le_province, '/content/drive/MyDrive/province_encoder.pkl')

# Buat ringkasan insight per cluster
def generate_insights_report(df):
    insights = []
    insights.append("=== EDUCATION DISPARITY INSIGHTS ===")
    clusters = sorted(df['cluster'].dropna().unique())

    insights.append(f"Total clusters identified: {len(clusters)}")

    for c in clusters:
        cl_data = df[df['cluster'] == c]

        # province tipikal
        if cl_data['province_name'].dropna().empty:
            typical_prov = "Unknown"
        else:
            typical_prov = cl_data['province_name'].mode()[0]

        insights.append(f"\n--- Cluster {int(c)} ---")
        insights.append(f"Typical Province        : {typical_prov}")
        insights.append(f"Avg Population Density  : {cl_data['population_density'].mean():.2f}")
        insights.append(f"Public School Ratio (0-1): {cl_data['is_public'].mean():.2f}")
        insights.append(f"Number of Schools       : {len(cl_data)}")

    return "\n".join(insights)

report_text = generate_insights_report(df_fe)
print(report_text)

# Simpan data hasil analisis dan laporan
df_fe.to_csv('/content/drive/MyDrive/analyzed_school_data.csv', index=False)

with open('/content/drive/MyDrive/education_analysis_report.txt', 'w') as f:
    f.write(report_text)

print("\n✅ Semua hasil disimpan ke Google Drive:")
print("- education_cluster_model.pkl")
print("- school_status_predictor.pkl")
print("- feature_scaler.pkl")
print("- province_encoder.pkl")
print("- analyzed_school_data.csv")
print("- education_analysis_report.txt")